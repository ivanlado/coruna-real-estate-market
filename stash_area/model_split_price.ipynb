{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, LeaveOneOut\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "from get_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database object created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivan\\Desktop\\Coding\\corunaRealEstateMarket\\bd.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, self.connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k for clustering zones: 4\n",
      "Column n_banos has more than 20% of missing values.\n",
      "Column n_plazas_garaje has more than 20% of missing values.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 724 entries, 0 to 723\n",
      "Data columns (total 99 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   zona_cluster                                724 non-null    float64\n",
      " 1   id                                          724 non-null    float64\n",
      " 2   titulo                                      724 non-null    object \n",
      " 3   descripcion                                 711 non-null    object \n",
      " 4   extra_info                                  720 non-null    object \n",
      " 5   n_habitaciones                              724 non-null    float64\n",
      " 6   tamano                                      724 non-null    float64\n",
      " 7   precio                                      724 non-null    float64\n",
      " 8   municipio                                   724 non-null    object \n",
      " 9   n_banos                                     724 non-null    float64\n",
      " 10  n_plazas_garaje                             724 non-null    float64\n",
      " 11  direccion                                   713 non-null    object \n",
      " 12  landmarks_cercanos                          713 non-null    object \n",
      " 13  piscina                                     724 non-null    float64\n",
      " 14  valoracion                                  724 non-null    float64\n",
      " 15  direccion_x                                 724 non-null    float64\n",
      " 16  direccion_y                                 724 non-null    float64\n",
      " 17  zona                                        724 non-null    object \n",
      " 18  zona_v2                                     724 non-null    object \n",
      " 19  precio_m2_medio_cluster                     724 non-null    float64\n",
      " 20  zona_cluster_0                              724 non-null    float64\n",
      " 21  zona_cluster_1                              724 non-null    float64\n",
      " 22  zona_cluster_2                              724 non-null    float64\n",
      " 23  zona_cluster_3                              724 non-null    float64\n",
      " 24  zona_cluster_4                              724 non-null    float64\n",
      " 25  zona_cluster_5                              724 non-null    float64\n",
      " 26  densidad                                    724 non-null    float64\n",
      " 27  pib_capita                                  724 non-null    float64\n",
      " 28  distancia_centro_coruna                     724 non-null    float64\n",
      " 29  distancia_centro_coruna*tam                 724 non-null    float64\n",
      " 30  distancia_centro_oleiros                    724 non-null    float64\n",
      " 31  distancia_centro_oleiros*tam                724 non-null    float64\n",
      " 32  vacacional                                  724 non-null    float64\n",
      " 33  parking                                     724 non-null    float64\n",
      " 34  estudiantes                                 724 non-null    float64\n",
      " 35  playa                                       724 non-null    float64\n",
      " 36  balcon                                      724 non-null    float64\n",
      " 37  trastero                                    724 non-null    float64\n",
      " 38  vistas                                      724 non-null    float64\n",
      " 39  sin_ascensor                                724 non-null    float64\n",
      " 40  profesores                                  724 non-null    float64\n",
      " 41  amueblado                                   724 non-null    float64\n",
      " 42  es_casa                                     724 non-null    float64\n",
      " 43  lujo                                        724 non-null    float64\n",
      " 44  urbanizacion                                724 non-null    float64\n",
      " 45  reformado                                   724 non-null    float64\n",
      " 46  seminuevo                                   724 non-null    float64\n",
      " 47  estrenar                                    724 non-null    float64\n",
      " 48  reformado_estrenar                          724 non-null    float64\n",
      " 49  reformado_estrenar_seminuevo_amueblado      724 non-null    float64\n",
      " 50  ubicacion_excepcional                       724 non-null    float64\n",
      " 51  duplex                                      724 non-null    float64\n",
      " 52  atico                                       724 non-null    float64\n",
      " 53  villa                                       724 non-null    float64\n",
      " 54  climalit                                    724 non-null    float64\n",
      " 55  aire_acondicionado                          724 non-null    float64\n",
      " 56  sin_muebles                                 724 non-null    float64\n",
      " 57  electrico                                   724 non-null    float64\n",
      " 58  transporte                                  724 non-null    float64\n",
      " 59  gastos_incluidos                            724 non-null    float64\n",
      " 60  soleado                                     724 non-null    float64\n",
      " 61  paseo_maritimo                              724 non-null    float64\n",
      " 62  equipado                                    724 non-null    float64\n",
      " 63  jardin                                      724 non-null    float64\n",
      " 64  exclusivo                                   724 non-null    float64\n",
      " 65  spa                                         724 non-null    float64\n",
      " 66  es_chalet                                   724 non-null    float64\n",
      " 67  padel                                       724 non-null    float64\n",
      " 68  gym                                         724 non-null    float64\n",
      " 69  de_diseÃ±o                                   724 non-null    float64\n",
      " 70  puntuacion                                  724 non-null    float64\n",
      " 71  puntuacion_lujo                             724 non-null    float64\n",
      " 72  puntuacion_lujo_2                           724 non-null    float64\n",
      " 73  palabras_bonitas                            724 non-null    float64\n",
      " 74  coruna                                      724 non-null    float64\n",
      " 75  centro_coruna                               724 non-null    float64\n",
      " 76  oleiros                                     724 non-null    float64\n",
      " 77  maianca                                     724 non-null    float64\n",
      " 78  art_berg_camb                               724 non-null    float64\n",
      " 79  puntuacion*tam                              724 non-null    float64\n",
      " 80  puntuacion_lujo*tam                         724 non-null    float64\n",
      " 81  puntuacion_lujo_2*tam                       724 non-null    float64\n",
      " 82  palabras_bonitas*tam                        724 non-null    float64\n",
      " 83  es_chalet*tam                               724 non-null    float64\n",
      " 84  estrenar*tam                                724 non-null    float64\n",
      " 85  reformado_estrenar_seminuevo_amueblado*tam  724 non-null    float64\n",
      " 86  amueblado*tam                               724 non-null    float64\n",
      " 87  estudiantes*tam                             724 non-null    float64\n",
      " 88  vacacional*tam                              724 non-null    float64\n",
      " 89  exclusivo*tam                               724 non-null    float64\n",
      " 90  piscina*tam                                 724 non-null    float64\n",
      " 91  sin_ascensor*tam                            724 non-null    float64\n",
      " 92  oleiros*tam                                 724 non-null    float64\n",
      " 93  maianca*tam                                 724 non-null    float64\n",
      " 94  art_berg_camb*tam                           724 non-null    float64\n",
      " 95  coruna*tam                                  724 non-null    float64\n",
      " 96  centro_coruna*tam                           724 non-null    float64\n",
      " 97  precio_m2_medio_cluster*tam                 724 non-null    float64\n",
      " 98  tamano^2                                    724 non-null    float64\n",
      "dtypes: float64(91), object(8)\n",
      "memory usage: 565.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ds, cols_model = get_data_model_v2(k_clusters=6)\n",
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds[cols_model].drop('precio', axis=1)\n",
    "y = ds['precio']\n",
    "\n",
    "# slit data into train and val\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train:\t mean 258.53\t std 12.13\n",
      "RMSE val:\t mean 361.61\t std 52.83\n",
      "\n",
      "MAE train:\t mean 167.69\t std 6.01\n",
      "MAE val:\t mean 214.92\t std 17.91\n"
     ]
    }
   ],
   "source": [
    "def train_model(x,y, model, n_splits=5, n_repeats=5, print_results=False):\n",
    "    return_val = []\n",
    "    rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    rkf.get_n_splits(x, y)\n",
    "    for i, (train_index, val_index) in enumerate(rkf.split(x)):\n",
    "        x_train = x.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        x_val = x.iloc[val_index]\n",
    "        y_val = y.iloc[val_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_val_pred = model.predict(x_val)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_val = mean_absolute_error(y_val, y_val_pred) \n",
    "        return_val.append({'rmse_train': rmse_train, 'rmse_val': rmse_val, 'mae_train': mae_train, 'mae_val': mae_val})\n",
    "    if print_results:\n",
    "        rmse_train = [x['rmse_train'] for x in return_val]\n",
    "        rmse_val = [x['rmse_val'] for x in return_val]\n",
    "        mae_train = [x['mae_train'] for x in return_val]\n",
    "        mae_val = [x['mae_val'] for x in return_val]\n",
    "\n",
    "        print(f'RMSE train:\\t mean {np.mean(rmse_train):.2f}\\t std {np.std(rmse_train):.2f}')\n",
    "        print(f'RMSE val:\\t mean {np.mean(rmse_val):.2f}\\t std {np.std(rmse_val):.2f}')\n",
    "        print(\"\")\n",
    "        print(f'MAE train:\\t mean {np.mean(mae_train):.2f}\\t std {np.std(mae_train):.2f}')\n",
    "        print(f'MAE val:\\t mean {np.mean(mae_val):.2f}\\t std {np.std(mae_val):.2f}')\n",
    "    return return_val\n",
    "    \n",
    "trainings = train_model(x,y, LinearRegression(), n_splits=5, n_repeats=5, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_split_model = ['tamano', 'n_habitaciones', 'vacacional', 'puntuacion', 'puntuacion_lujo', 'puntuacion_lujo_2', 'palabras_bonitas', 'centro_coruna', 'maianca']\n",
    "x = ds[cols_split_model]\n",
    "y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary class price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_binary_eval(x,y, model, boundary, n_splits=5, n_repeats=5, print_results=False):\n",
    "    return_val = []\n",
    "    rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    rkf.get_n_splits(x, y)\n",
    "    for i, (train_index, val_index) in enumerate(rkf.split(x)):\n",
    "        x_train = x.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        x_val = x.iloc[val_index]\n",
    "        y_val = y.iloc[val_index]\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_train = y_train > boundary\n",
    "        y_val = y_val > boundary\n",
    "\n",
    "        y_train_pred = model.predict(x_train) > boundary\n",
    "        y_val_pred = model.predict(x_val) > boundary\n",
    "\n",
    "        # count true positive\n",
    "        tp_train = sum(y_train_pred * y_train)\n",
    "        tp_val = sum(y_val_pred * y_val)\n",
    "\n",
    "        # count false positive\n",
    "        fp_train = sum(y_train_pred & ~y_train)\n",
    "        fp_val = sum(y_val_pred & ~y_val)\n",
    "\n",
    "        # count false negative\n",
    "        fn_train = sum(~y_train_pred & y_train)\n",
    "        fn_val = sum(~y_val_pred & y_val)\n",
    "\n",
    "        # count true negative\n",
    "        tn_train = sum(~y_train_pred & ~y_train)\n",
    "        tn_val = sum(~y_val_pred & ~y_val)\n",
    "\n",
    "        # calculate precision\n",
    "        precision_train = tp_train / (tp_train + fp_train)\n",
    "\n",
    "        # calculate recall\n",
    "        recall_train = tp_train / (tp_train + fn_train)\n",
    "\n",
    "        # calculate f1 score\n",
    "        f1_train = 2 * (precision_train * recall_train) / (precision_train + recall_train)\n",
    "\n",
    "        # calculate precision\n",
    "        precision_val = tp_val / (tp_val + fp_val)\n",
    "\n",
    "        # calculate recall\n",
    "        recall_val = tp_val / (tp_val + fn_val)\n",
    "\n",
    "        # calculate f1 score\n",
    "        f1_val = 2 * (precision_val * recall_val) / (precision_val + recall_val)\n",
    "\n",
    "        train = {'tp': tp_train, 'fp': fp_train, 'fn': fn_train, 'tn': tn_train, 'precision': precision_train, 'recall': recall_train, 'f1': f1_train}\n",
    "        val = {'tp': tp_val, 'fp': fp_val, 'fn': fn_val, 'tn': tn_val, 'precision': precision_val, 'recall': recall_val, 'f1': f1_val}\n",
    "        return_val.append({'train': train, 'val': val})\n",
    "\n",
    "    if print_results:\n",
    "        precision_train = [x['train']['precision'] for x in return_val]\n",
    "        precision_val = [x['val']['precision'] for x in return_val]\n",
    "        f1_train = [x['train']['f1'] for x in return_val]\n",
    "        f1_val = [x['val']['f1'] for x in return_val] \n",
    "\n",
    "        print(f'Precision train:\\t mean {np.mean(precision_train):.2f}\\t std {np.std(precision_train):.2f}')\n",
    "        print(f'Precision val:\\t mean {np.mean(precision_val):.2f}\\t std {np.std(precision_val):.2f}')\n",
    "        print(\"\")\n",
    "        print(f'F1 train:\\t mean {np.mean(f1_train):.2f}\\t std {np.std(f1_train):.2f}')\n",
    "        print(f'F1 val:\\t mean {np.mean(f1_val):.2f}\\t std {np.std(f1_val):.2f}')\n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train:\t mean 334.28\t std 15.12\n",
      "RMSE val:\t mean 344.06\t std 55.58\n",
      "\n",
      "MAE train:\t mean 213.44\t std 7.10\n",
      "MAE val:\t mean 219.38\t std 19.40\n"
     ]
    }
   ],
   "source": [
    "trainings = train_model(x,y, LinearRegression(), n_splits=5, n_repeats=5, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision train:\t mean 0.66\t std 0.03\n",
      "Precision val:\t mean 0.64\t std 0.15\n",
      "\n",
      "F1 train:\t mean 0.65\t std 0.03\n",
      "F1 val:\t mean 0.63\t std 0.12\n"
     ]
    }
   ],
   "source": [
    "trainings = train_model_binary_eval(x,y, LinearRegression(), 1500, n_splits=5, n_repeats=5, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472    1800.0\n",
      "560    1890.0\n",
      "481    1850.0\n",
      "471    2400.0\n",
      "Name: precio, dtype: float64 --- [ 778.31161847 1268.62137509 1490.96773458 1127.22786273]\n",
      "602    1000.0\n",
      "452    1100.0\n",
      "557    1250.0\n",
      "Name: precio, dtype: float64 --- [1585.04123192 1789.06330059 1618.99175008]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(y_test[(y_test>1500)&(y_test_pred<1500)], '---' , y_test_pred[(y_test>1500)&(y_test_pred<1500)])\n",
    "print(y_test[(y_test<1500)&(y_test_pred>1500)], '---' , y_test_pred[(y_test<1500)&(y_test_pred>1500)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:\t mean 0.97\t std 0.01\n",
      "Accuracy val:\t mean 0.93\t std 0.03\n",
      "\n",
      "F1 train:\t mean 0.83\t std 0.02\n",
      "F1 val:\t mean 0.63\t std 0.13\n"
     ]
    }
   ],
   "source": [
    "acc_train = []\n",
    "acc_val = []\n",
    "f1_train = []\n",
    "f1_val = []\n",
    "\n",
    "yy = y > 1500\n",
    "\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, yy, test_size=0.1)\n",
    "    class_ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',  # For binary classification\n",
    "        max_depth=3,  # Maximum depth of a tree\n",
    "        learning_rate=0.1,  # Step size shrinkage\n",
    "        n_estimators=100,  # Number of boosting rounds (trees)\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        random_state=42,  # For reproducibility\n",
    "        scale_pos_weight=class_ratio\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy_train = accuracy_score(y_train, clf.predict(X_train))\n",
    "    accuracy_val = accuracy_score(y_test, y_pred)\n",
    "    f1_tr = f1_score(y_train, clf.predict(X_train))\n",
    "    f1_va = f1_score(y_test, y_pred)\n",
    "    acc_train.append(accuracy_train)\n",
    "    acc_val.append(accuracy_val)\n",
    "    f1_train.append(f1_tr)\n",
    "    f1_val.append(f1_va)\n",
    "\n",
    "print(f'Accuracy train:\\t mean {np.mean(acc_train):.2f}\\t std {np.std(acc_train):.2f}')\n",
    "print(f'Accuracy val:\\t mean {np.mean(acc_val):.2f}\\t std {np.std(acc_val):.2f}')\n",
    "print(\"\")\n",
    "print(f'F1 train:\\t mean {np.mean(f1_train):.2f}\\t std {np.std(f1_train):.2f}')\n",
    "print(f'F1 val:\\t mean {np.mean(f1_val):.2f}\\t std {np.std(f1_val):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "acc_train = []\n",
    "acc_val = []\n",
    "f1_train = []\n",
    "f1_val = []\n",
    "\n",
    "y_test_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "yy = y > 1500\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "for i, (train_index, test_index) in enumerate(loo.split(x)):\n",
    "    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = yy.iloc[train_index], yy.iloc[test_index]\n",
    "    class_ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "    clf = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',  # For binary classification\n",
    "        max_depth=3,  # Maximum depth of a tree\n",
    "        learning_rate=0.1,  # Step size shrinkage\n",
    "        n_estimators=100,  # Number of boosting rounds (trees)\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        random_state=42,  # For reproducibility\n",
    "        scale_pos_weight=class_ratio\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_test_list.append(y_test.values[0])\n",
    "    y_pred_list.append(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test:\t mean 0.92\n",
      "F1 test:\t mean 0.60\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test_list, y_pred_list)\n",
    "f1_test = f1_score(y_test_list, y_pred_list)\n",
    "\n",
    "print(f'Accuracy test:\\t mean {accuracy_test:.2f}')\n",
    "print(f'F1 test:\\t mean {f1_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train:\t mean 172.50\t std 3.52\n",
      "RMSE val:\t mean 176.87\t std 14.13\n",
      "\n",
      "MAE train:\t mean 129.69\t std 2.68\n",
      "MAE val:\t mean 132.89\t std 10.14\n",
      "\n",
      "\n",
      "\n",
      "RMSE train:\t mean 616.73\t std 35.07\n",
      "RMSE val:\t mean 747.26\t std 140.02\n",
      "\n",
      "MAE train:\t mean 473.03\t std 22.39\n",
      "MAE val:\t mean 579.37\t std 85.13\n"
     ]
    }
   ],
   "source": [
    "split_model = clf\n",
    "\n",
    "x = ds[cols_model]\n",
    "x = x.drop('precio', axis=1)\n",
    "\n",
    "xx = x[cols_split_model]\n",
    "predict_classes = split_model.predict(xx)\n",
    "x_low = xx.iloc[np.where(predict_classes == 0)[0]]\n",
    "y_low = y.iloc[np.where(predict_classes == 0)[0]]\n",
    "x_high = xx.iloc[np.where(predict_classes == 1)[0]]\n",
    "y_high = y.iloc[np.where(predict_classes == 1)[0]]\n",
    "\n",
    "trainings = train_model(x_low, y_low, LinearRegression(), n_splits=5, n_repeats=5, print_results=True)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "trainings = train_model(x_high, y_high, LinearRegression(), n_splits=5, n_repeats=5, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248.55801104972375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(x_low)*176 + len(x_high)*747)/(len(x_low) + len(x_high))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
